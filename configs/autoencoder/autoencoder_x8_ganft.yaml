# TRAINING
logging:
  save_dir: "checkpoints/autoencoder_x8_ganft"
  allow_overwrite: false
  plot_epochs: 50
  save_epochs: 5
  temp_save_epochs: 1
  seed: 74

training:
  train_batch_size: 64
  gradient_accumulation_steps: 1
  gradient_clip_val: 5
  mixed_precision: "fp16"
  epochs: 150
  epoch_steps: 1024
  seed: 74
  kl_weight: 0.05
  warmup_steps: 1024
  tasks:
    - name: residual
      channels: 1
      losses: ["mse", "percep"]
      weights: [0.5, 0.5]
      task_weight: 0.5
    - name: watercover
      channels: 1
      losses: ["bce"]
      weights: [1]
      task_weight: 0.2
  encoder_only: false
  discriminator_weight: 1.0
  r_gamma: 0.005
  r_interval: 1
  disc_lr_mult: 1
  burnin_steps: 20480
  r_warmup_factor: 1
  lr_warmup_factor: 1
  disc_lr_warmup_factor: 1
  sigmoid_channels: [1]

evaluation:
  validate_epochs: 5
  val_ema_idx: 0
  validation_steps: 16384
  training_eval: true
  mse_scale_eps: 0.05
  eval_fid: true

optimizer:
  type: "adam"
  kwargs:
    betas: [0.0, 0.99]

ema:
  sigma_rels: [0.05, 0.1]
  update_every: 1
  checkpoint_every_num_steps: 1024

wandb:
  project: "generative_land"
  tags: ["64x64->512x512", "autoencoder"]
  mode: "online"
  save_code: true

model:
  "@model": "autoencoder"
  image_size: 512
  in_channels: 2
  out_channels: 2
  model_channels: 64
  model_channel_mults: [1, 2, 4, 4]
  layers_per_block: 2
  emb_channels: null
  noise_emb_dims: 0
  custom_cond_emb_dims: null
  attn_resolutions: []
  midblock_attention: false
  concat_balance: 0.5
  latent_channels: 4
  conditional_inputs: []
  direct_skips: []

#discriminator:
#  "@model": discriminator
#  in_channels: 2
#  additional_vars: 0
#  additional_vars_hidden: 0
#  model_channels: 64
#  channel_mults: [1, 2, 4, 4]
#  layers_per_block: 2
#  dropout: 0.0
#  noise_level: 0.0

discriminator:
  "@model": discriminator_basic
  in_channels: 2
  model_channels: 64
  n_layers: 4

lr_sched:
  "@lr_sched": "constant"
  lr: 0.00005

train_dataset:
  "@dataset": "h5_autoencoder"
  h5_file: "data/dataset.h5"
  crop_size: 64
  pct_land_ranges: [[0, 0.01],[0.01, 1]]
  subset_resolutions: [90, 90]
  subset_weights: [0.01, 1]
  split: "train"

val_dataset:
  "@dataset": "h5_autoencoder"
  h5_file: "data/dataset.h5"
  crop_size: 64
  pct_land_ranges: [[0, 0.01], [0.01, 1]]
  subset_resolutions: [90, 90]
  subset_weights: [0.01, 1]
  split: "val"

dataloader_kwargs:
  num_workers: 15
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: true
