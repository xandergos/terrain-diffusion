# TRAINING
logging:
  save_dir: "checkpoints/autoencoder_x8_ganft_fast_g0.02"
  allow_overwrite: false
  plot_epochs: 50
  save_epochs: 5
  temp_save_epochs: 1
  seed: 74

training:
  train_batch_size: 32
  gradient_accumulation_steps: 1
  gradient_clip_val: 500
  mixed_precision: "fp16"
  epochs: 1500
  epoch_steps: 1024
  seed: 74
  kl_weight: 0.005
  tasks:
    - name: residual
      channels: 1
      losses: ["mse", "percep"]
      weights: [0.5, 0.5]
      task_weight: 0.5
    - name: watercover
      channels: 1
      losses: ["mse"]
      weights: [1]
      task_weight: 0.5
  decoder_only: false
  discriminator_weight: 1.0
  r_gamma: 0.02
  r_interval: 1
  disc_lr_mult: 1.0
  burnin_steps: 10240
  r_warmup_factor: 1
  lr_warmup_factor: 1
  task_weight_warmup_factor: 1
  disc_lr_warmup_factor: 1
  disc_weight_warmup_factor: 1
  sigmoid_channels: []

evaluation:
  validate_epochs: 5
  val_ema_idx: 0
  validation_steps: 16384
  training_eval: true
  mse_scale_eps: 0.05
  eval_fid: true

optimizer:
  type: "adam"
  kwargs:
    betas: [0.0, 0.99]

optimizer_d:
  type: "adam"
  kwargs:
    betas: [0.0, 0.99]

ema:
  sigma_rels: [0.05, 0.1]
  update_every: 1
  checkpoint_every_num_steps: 1024

wandb:
  project: "generative_land"
  tags: ["64x64->512x512", "autoencoder", "gan"]
  mode: "online"
  save_code: true

model:
  "@model": "edm_autoencoder"
  image_size: 512
  in_channels: 2
  out_channels: 2
  model_channels: 64
  model_channel_mults: [1, 2, 4, 4]
  layers_per_block: 2
  emb_channels: null
  noise_emb_dims: 0
  custom_cond_emb_dims: null
  attn_resolutions: []
  midblock_attention: false
  concat_balance: 0.5
  latent_channels: 4
  conditional_inputs: []
  direct_skips: []


discriminator:
  "@model": discriminator
  in_channels: 2
  model_channels: 64
  channel_mults: [1, 2, 4, 4, 4]
  layers_per_block: 2
  dropout: 0.0
  noise_level: 0.0
  channel_means: [0.0, 0.5]
  channel_stds: [1.0, 0.5]

lr_sched:
  "@lr_sched": "constant"
  lr: 0.00005

train_dataset:
  "@dataset": "h5_autoencoder"
  h5_file: "data/dataset.h5"
  crop_size: 64
  pct_land_ranges: [[0, 0.01], [0.01, 1]]
  subset_resolutions: [90, 90]
  subset_weights: [0.01, 1]
  split: "train"
  channel_means: [0.00216, 0.08018]
  channel_stds: [1.1678, 0.26459]

val_dataset:
  "@dataset": "h5_autoencoder"
  h5_file: "data/dataset.h5"
  crop_size: 128
  pct_land_ranges: [[0, 0.01], [0.01, 1]]
  subset_resolutions: [90, 90]
  subset_weights: [0.01, 1]
  split: "val"
  channel_means: [0.00216, 0.08018]
  channel_stds: [1.1678, 0.26459]

dataloader_kwargs:
  num_workers: 15
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: true
